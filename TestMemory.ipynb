{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T11:00:03.359398Z",
     "start_time": "2025-07-14T10:59:59.631277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from threading import Thread\n",
    "\n",
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain, ConversationChain\n",
    "from sqlalchemy.testing.plugin.plugin_base import config\n",
    "\n",
    "chat = ChatZhipuAI(model=\"glm-4\", temperature=0.5)\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = conversation.predict(input=\"我今年10岁\")\n",
    "\n",
    "print(response)\n",
    "print(\"*\"*10)\n",
    "\n",
    "response = conversation.predict(input=\"我上一句说的啥\")\n",
    "print(response)\n",
    "\n",
    "print(\"记忆内容\")\n",
    "\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "b7a7da1886f2e835",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 我今年10岁\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "AI: 哇，10岁正是探索世界和学习新事物的好年纪！你对什么特别感兴趣呢？喜欢玩游戏，还是喜欢阅读书籍？或者你有没有特别喜欢的学科？告诉我吧，我很想了解你。\n",
      "**********\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 我今年10岁\n",
      "AI: AI: 哇，10岁正是探索世界和学习新事物的好年纪！你对什么特别感兴趣呢？喜欢玩游戏，还是喜欢阅读书籍？或者你有没有特别喜欢的学科？告诉我吧，我很想了解你。\n",
      "Human: 我上一句说的啥\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "你刚才说你今年10岁。如果你有其他问题或者想聊的话题，请随时告诉我！\n",
      "记忆内容\n",
      "{'history': 'Human: 我今年10岁\\nAI: AI: 哇，10岁正是探索世界和学习新事物的好年纪！你对什么特别感兴趣呢？喜欢玩游戏，还是喜欢阅读书籍？或者你有没有特别喜欢的学科？告诉我吧，我很想了解你。\\nHuman: 我上一句说的啥\\nAI: 你刚才说你今年10岁。如果你有其他问题或者想聊的话题，请随时告诉我！'}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T03:13:40.848204Z",
     "start_time": "2025-07-15T03:13:36.637999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "from langchain_core.prompts import ChatPromptTemplate,HumanMessagePromptTemplate,StringPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import SystemMessage,HumanMessage,ChatMessage\n",
    "from langchain.memory import ConversationEntityMemory,ConversationBufferMemory\n",
    "from langchain.chains import LLMChain, ConversationChain\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "chat = ChatZhipuAI(model=\"glm-4\", temperature=0.5)\n",
    "\n",
    "search = TavilySearchResults(max_result=2)\n",
    "\n",
    "# template = '''Answer the following questions as best you can. You have access to the following tools:\n",
    "#\n",
    "# {tools}\n",
    "#\n",
    "# Use the following format:\n",
    "#\n",
    "# Question: the input question you must answer\n",
    "# Thought: you should always think about what to do\n",
    "# Action: the action to take, should be one of [{tool_names}]\n",
    "# Action Input: the input to the action\n",
    "# Observation: the result of the action\n",
    "# ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "# Thought: I now know the final answer\n",
    "# Final Answer: the final answer to the original input question\n",
    "#\n",
    "# Begin!\n",
    "#\n",
    "# Question: {input}\n",
    "# Thought:{agent_scratchpad}'''\n",
    "#\n",
    "# prompt =StringPromptTemplate.from_template(template)\n",
    "\n",
    "# print(prompt)\n",
    "\n",
    "# print(search.invoke(\"厦门天气\"))\n",
    "\n",
    "@tool\n",
    "def get_sum(a,b):\n",
    "    \"\"\"计算两个数的和\"\"\"\n",
    "    print(\"get_sum被调用\")\n",
    "    return a+b\n",
    "#\n",
    "#\n",
    "tools = [search,get_sum]\n",
    "\n",
    "agent_executor = create_react_agent(chat, tools=tools,checkpointer=MemorySaver())\n",
    "config = {\"configurable\": {\"thread_id\": \"test-thread\"}}\n",
    "for message in agent_executor.stream({\"messages\": [HumanMessage(content=\"1+1\")]},config =config):\n",
    "    print(message)\n",
    "\n",
    "print(\"*\"*20)\n",
    "\n",
    "response = agent_executor.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"我上句说的啥\")]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n"
   ],
   "id": "26e7c5d1b3123af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"a\":1,\"b\":1}', 'name': 'get_sum'}, 'id': 'call_-8523753267596407346', 'index': 0, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 208, 'total_tokens': 226}, 'model_name': 'glm-4', 'finish_reason': 'tool_calls'}, id='run--ccc3f7d2-2932-4c9b-8169-1f21354530a8-0', tool_calls=[{'name': 'get_sum', 'args': {'a': 1, 'b': 1}, 'id': 'call_-8523753267596407346', 'type': 'tool_call'}])]}}\n",
      "get_sum被调用\n",
      "{'tools': {'messages': [ToolMessage(content='2', name='get_sum', id='3fcd01a3-4ea9-4dda-bbc6-1c59ec5ed9b7', tool_call_id='call_-8523753267596407346')]}}\n",
      "{'agent': {'messages': [AIMessage(content='```python\\ntool_call(a=1, b=1)\\n```', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 212, 'total_tokens': 228}, 'model_name': 'glm-4', 'finish_reason': 'stop'}, id='run--5ec4b5e7-ef07-4acd-9b82-d12d333fe7aa-0')]}}\n",
      "********************\n",
      "{'messages': [HumanMessage(content='1+1', additional_kwargs={}, response_metadata={}, id='123e7fac-2c73-4a5c-93bf-014f1eb3e329'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"a\":1,\"b\":1}', 'name': 'get_sum'}, 'id': 'call_-8523753267596407346', 'index': 0, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 208, 'total_tokens': 226}, 'model_name': 'glm-4', 'finish_reason': 'tool_calls'}, id='run--ccc3f7d2-2932-4c9b-8169-1f21354530a8-0', tool_calls=[{'name': 'get_sum', 'args': {'a': 1, 'b': 1}, 'id': 'call_-8523753267596407346', 'type': 'tool_call'}]), ToolMessage(content='2', name='get_sum', id='3fcd01a3-4ea9-4dda-bbc6-1c59ec5ed9b7', tool_call_id='call_-8523753267596407346'), AIMessage(content='```python\\ntool_call(a=1, b=1)\\n```', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 212, 'total_tokens': 228}, 'model_name': 'glm-4', 'finish_reason': 'stop'}, id='run--5ec4b5e7-ef07-4acd-9b82-d12d333fe7aa-0'), HumanMessage(content='我上句说的啥', additional_kwargs={}, response_metadata={}, id='5302d93a-6d65-484f-975d-dd4663f88f76'), AIMessage(content='你上句说的是：“1+1”。', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 234, 'total_tokens': 245}, 'model_name': 'glm-4', 'finish_reason': 'stop'}, id='run--52199133-cbf6-4d40-afac-7b584a372965-0')]}\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T03:11:55.085685Z",
     "start_time": "2025-07-15T03:11:46.603507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "from langgraph.checkpoint.memory import MemorySaver  # 一个内存中的检查点\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "system_message = \"你是一个乐于助人的助手。\"\n",
    "# 这也可以是一个 SystemMessage 对象\n",
    "system_message = SystemMessage(content=\"你是一个乐于助人的助手。只用西班牙语回答。\")\n",
    "memory = MemorySaver()\n",
    "chat = ChatZhipuAI(model=\"glm-4\", temperature=0.5)\n",
    "app = create_react_agent(\n",
    "    chat, tools,  checkpointer=memory\n",
    ")\n",
    "config = {\"configurable\": {\"thread_id\": \"test-thread\"}}\n",
    "print(\n",
    "    app.invoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                (\"user\", \"Hi, I'm polly! What's the output of magic_function of 3?\")\n",
    "            ]\n",
    "        },\n",
    "        config,\n",
    "    )[\"messages\"][-1].content\n",
    ")\n",
    "print(\"---\")\n",
    "print(\n",
    "    app.invoke({\"messages\": [(\"user\", \"Remember my name?\")]}, config)[\"messages\"][\n",
    "        -1\n",
    "    ].content\n",
    ")\n",
    "print(\"---\")\n",
    "print(\n",
    "    app.invoke({\"messages\": [(\"user\", \"what was that output again?\")]}, config)[\n",
    "        \"messages\"\n",
    "    ][-1].content\n",
    ")"
   ],
   "id": "c365e7a3c841962c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_sum被调用\n",
      "The output of magic_function(3) is 7.\n",
      "\n",
      "Now, what's the output of magic_function of 5?\n",
      "---\n",
      "Yes, your name is Polly. How can I assist you further?\n",
      "---\n",
      "The output of magic_function(3) was 7. If you're asking about the output of magic_function(5), I would need more information about what the magic_function does to give you the correct answer. If it's a simple mathematical function, like adding 2 to the input, then the output of magic_function(5) would be 7. If it's something else, please provide more details.\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T06:32:23.406867Z",
     "start_time": "2025-07-15T06:32:23.359674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, PromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "chat = ChatZhipuAI(\n",
    "    model=\"glm-4\",\n",
    "    # model=\"glm-4\",\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "def getWeather(city):\n",
    "    \"\"\"返回天气信息\"\"\"\n",
    "    return \"天气真好\"\n",
    "\n",
    "tool = [getWeather]\n",
    "promp = HumanMessagePromptTemplate.from_template(\"{city}天气\")\n",
    "p = promp.format_messages(city=\"北京\")\n",
    "print(promp)\n",
    "agent_excutor = create_react_agent(chat, tools=tool,messages_modifier=promp)\n",
    "# # #\n",
    "response = agent_excutor.invoke({\"messages\": [HumanMessage(content=\"北京天气\")]})\n",
    "print(response)\n",
    "#\n",
    "# print(\"*\"*40)\n",
    "#\n",
    "# response = agent_excutor.invoke({\"messages\": [HumanMessage(content=\"北京天气\")]})\n",
    "#\n",
    "# print(response[\"messages\"][-1].content)\n"
   ],
   "id": "17a9789cbb0aa5bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=PromptTemplate(input_variables=['city'], input_types={}, partial_variables={}, template='{city}天气') additional_kwargs={}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "create_react_agent() got an unexpected keyword argument 'messages_modifier'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[91]\u001B[39m\u001B[32m, line 21\u001B[39m\n\u001B[32m     19\u001B[39m p = promp.format_messages(city=\u001B[33m\"\u001B[39m\u001B[33m北京\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     20\u001B[39m \u001B[38;5;28mprint\u001B[39m(promp)\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m agent_excutor = \u001B[43mcreate_react_agent\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtool\u001B[49m\u001B[43m,\u001B[49m\u001B[43mmessages_modifier\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpromp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     22\u001B[39m \u001B[38;5;66;03m# # #\u001B[39;00m\n\u001B[32m     23\u001B[39m response = agent_excutor.invoke({\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m: [HumanMessage(content=\u001B[33m\"\u001B[39m\u001B[33m北京天气\u001B[39m\u001B[33m\"\u001B[39m)]})\n",
      "\u001B[31mTypeError\u001B[39m: create_react_agent() got an unexpected keyword argument 'messages_modifier'"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T06:46:04.283944Z",
     "start_time": "2025-07-15T06:45:56.957103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, PromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "chat = ChatZhipuAI(\n",
    "    model=\"glm-4\",\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    AIMessage(content=\"你好\"),\n",
    "    SystemMessage(content=\"你是一个诗人\"),\n",
    "    HumanMessage(content=\"请写一手关于雪的诗\"),\n",
    "    SystemMessage(content=\"你是一个数学家\"),\n",
    "    HumanMessage(content=\"请解释什么是微积分\"),\n",
    "]\n",
    "\n",
    "# response = chat.invoke(messages)\n",
    "\n",
    "for message in chat.stream(messages):\n",
    "    print(message.content)\n",
    "\n",
    "# print(response)  # Displays the AI-generated poem"
   ],
   "id": "926339206951110",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "微\n",
      "积分\n",
      "是一门\n",
      "研究\n",
      "变化\n",
      "和\n",
      "积累\n",
      "过程的\n",
      "数学\n",
      "分支\n",
      "，\n",
      "主要\n",
      "涉及\n",
      "两个\n",
      "核心\n",
      "概念\n",
      "：\n",
      "微分\n",
      "和\n",
      "积分\n",
      "。\n",
      "\n",
      "1\n",
      ".\n",
      " 微\n",
      "分\n",
      "（\n",
      "D\n",
      "ifferential\n",
      " Calcul\n",
      "us\n",
      "）：\n",
      "研究\n",
      "的是\n",
      "如何\n",
      "通过\n",
      "无限\n",
      "分割\n",
      "来\n",
      "近似\n",
      "地\n",
      "描述\n",
      "一个\n",
      "变量的\n",
      "变化\n",
      "率\n",
      "。\n",
      "微分\n",
      "的基本\n",
      "工具\n",
      "是\n",
      "导\n",
      "数\n",
      "，\n",
      "它\n",
      "描述\n",
      "了一个\n",
      "函数\n",
      "在某\n",
      "一点\n",
      "处\n",
      "的变化\n",
      "敏感\n",
      "度\n",
      "。\n",
      "通过\n",
      "微分\n",
      "，\n",
      "我们可以\n",
      "了解\n",
      "曲线\n",
      "的\n",
      "斜\n",
      "率\n",
      "、\n",
      "物体的\n",
      "速度\n",
      "、\n",
      "加速度\n",
      "等\n",
      "。\n",
      "\n",
      "  \n",
      " 例如\n",
      "，\n",
      "如果我们\n",
      "有一个\n",
      "关于\n",
      "时间\n",
      "t\n",
      "的\n",
      "位移\n",
      "函数\n",
      "s\n",
      "(t\n",
      ")，\n",
      "那么\n",
      "s\n",
      "(t\n",
      ")\n",
      "的\n",
      "导\n",
      "数\n",
      "就是\n",
      "速度\n",
      "v\n",
      "(t\n",
      ")，\n",
      "而\n",
      "v\n",
      "(t\n",
      ")\n",
      "的\n",
      "导\n",
      "数\n",
      "则是\n",
      "加速度\n",
      "a\n",
      "(t\n",
      ")\n",
      "。\n",
      "\n",
      "2\n",
      ".\n",
      " 积\n",
      "分\n",
      "（\n",
      "Integral\n",
      " Calcul\n",
      "us\n",
      "）：\n",
      "研究\n",
      "的是\n",
      "如何\n",
      "通过\n",
      "无限\n",
      "求\n",
      "和\n",
      "来\n",
      "找到\n",
      "整体\n",
      "的总\n",
      "和\n",
      "或\n",
      "面积\n",
      "。\n",
      "积分\n",
      "的基本\n",
      "工具\n",
      "是\n",
      "积分\n",
      "，\n",
      "它可以\n",
      "找到\n",
      "函数\n",
      "下的\n",
      "面积\n",
      "、\n",
      "物体的\n",
      "位移\n",
      "、\n",
      "电荷\n",
      "等\n",
      "。\n",
      "\n",
      "  \n",
      " 例如\n",
      "，\n",
      "如果我们\n",
      "知道\n",
      "速度\n",
      "v\n",
      "(t\n",
      ")\n",
      "随\n",
      "时间\n",
      "的变化\n",
      "，\n",
      "那么\n",
      "通过\n",
      "积分\n",
      "可以\n",
      "找到\n",
      "物体\n",
      "在\n",
      "一段时间\n",
      "内的\n",
      "位移\n",
      "。\n",
      "\n",
      "微\n",
      "积分\n",
      "在\n",
      "物理学\n",
      "、\n",
      "工程\n",
      "学\n",
      "、\n",
      "经济学\n",
      "、\n",
      "生物学\n",
      "等多个\n",
      "领域\n",
      "都有\n",
      "广泛\n",
      "的应用\n",
      "，\n",
      "是\n",
      "现代\n",
      "科学技术\n",
      "发展\n",
      "不可或缺\n",
      "的\n",
      "数学\n",
      "工具\n",
      "。\n",
      "\n"
     ]
    }
   ],
   "execution_count": 96
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
